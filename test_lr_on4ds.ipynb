{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.lda import LDA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X1, y1 = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                           random_state=1, n_clusters_per_class=1)\n",
    "rng = np.random.RandomState(2)\n",
    "X1 += 2 * rng.uniform(size=X1.shape)\n",
    "\n",
    "X2,y2=make_moons(noise=0.3, random_state=0)\n",
    "X3,y3=make_circles(noise=0.2, factor=0.5, random_state=1)\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X4 = iris.data\n",
    "y4 = iris.target\n",
    "dataset=[(X1,y1),\n",
    "         (X2,y2),\n",
    "         (X3,y3),\n",
    "         (X4,y4)\n",
    "        ]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.942 0.940 0.910\n",
      "0.835 0.847 0.790\n",
      "0.425 0.430 0.438\n",
      "0.870 0.880 0.923\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for  ds in dataset:\n",
    "    sumlda=0\n",
    "    sumpca=0\n",
    "    sumkpca=0\n",
    "    n_c=2\n",
    "    for ite in range(10):\n",
    "        # preprocess dataset, split into training and test part\n",
    "        X, y = ds    \n",
    "        X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size=.4, random_state=ite)\n",
    "        pca = PCA(n_components=n_c)\n",
    "        X_pca = pca.fit(X_train).transform(X_train)\n",
    "        X_pca_test=pca.transform(X_test)\n",
    "\n",
    "\n",
    "        lda = LDA(n_components=n_c)\n",
    "        X_lda = lda.fit(X_train,y_train).transform(X_train)\n",
    "        X_lda_test=lda.transform(X_test)\n",
    "\n",
    "        kpca = KernelPCA(n_components=n_c,kernel=\"rbf\", gamma=1)\n",
    "        X_kpca = kpca.fit(X_train).transform(X_train)\n",
    "        X_kpca_test=kpca.transform(X_test)\n",
    "\n",
    "        lr = LogisticRegression()\n",
    "        lr.fit(X_pca,y_train)\n",
    "        acc_pca=lr.score(X_pca_test,y_test)\n",
    "      \n",
    "        lr.fit(X_lda,y_train)\n",
    "        acc_lda=lr.score(X_lda_test,y_test)\n",
    "       \n",
    "        lr.fit(X_kpca,y_train)\n",
    "        acc_kpca=lr.score(X_kpca_test,y_test)\n",
    "        #print(acc_pca,acc_lda,acc_kpca)\n",
    "        sumpca+=acc_pca\n",
    "        sumlda+=acc_lda\n",
    "        sumkpca+=acc_kpca  \n",
    "    print(\"%.3f %.3f %.3f\"%(sumpca/10,sumlda/10,sumkpca/10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.940 0.940 0.905\n",
      "0.733 0.847 0.783\n",
      "0.458 0.430 0.448\n",
      "0.862 0.940 0.697\n"
     ]
    }
   ],
   "source": [
    "for  ds in dataset:\n",
    "    sumlda=0\n",
    "    sumpca=0\n",
    "    sumkpca=0\n",
    "    n_c=1\n",
    "    for ite in range(10):\n",
    "        # preprocess dataset, split into training and test part\n",
    "        X, y = ds    \n",
    "        X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size=.4, random_state=ite)\n",
    "        pca = PCA(n_components=n_c)\n",
    "        X_pca = pca.fit(X_train).transform(X_train)\n",
    "        X_pca_test=pca.transform(X_test)\n",
    "\n",
    "\n",
    "        lda = LDA(n_components=n_c)\n",
    "        X_lda = lda.fit(X_train,y_train).transform(X_train)\n",
    "        X_lda_test=lda.transform(X_test)\n",
    "\n",
    "        kpca = KernelPCA(n_components=n_c,kernel=\"rbf\", gamma=1)\n",
    "        X_kpca = kpca.fit(X_train).transform(X_train)\n",
    "        X_kpca_test=kpca.transform(X_test)\n",
    "\n",
    "        lr = LogisticRegression()\n",
    "        lr.fit(X_pca,y_train)\n",
    "        acc_pca=lr.score(X_pca_test,y_test)\n",
    "      \n",
    "        lr.fit(X_lda,y_train)\n",
    "        acc_lda=lr.score(X_lda_test,y_test)\n",
    "       \n",
    "        lr.fit(X_kpca,y_train)\n",
    "        acc_kpca=lr.score(X_kpca_test,y_test)\n",
    "        #print(acc_pca,acc_lda,acc_kpca)\n",
    "        sumpca+=acc_pca\n",
    "        sumlda+=acc_lda\n",
    "        sumkpca+=acc_kpca  \n",
    "    print(\"%.3f %.3f %.3f\"%(sumpca/10,sumlda/10,sumkpca/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
